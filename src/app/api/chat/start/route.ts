import { NextResponse } from 'next/server';
import { db } from '@/lib/firebase/firebase';
import { DraftConversation } from '@/lib/types/conversation';
import { collection, doc, setDoc, getDoc, doc as adminDoc } from 'firebase/firestore';
import { getAuth } from 'firebase-admin/auth';
import { adminApp } from '@/lib/firebase/admin';
import { genAI, buildRequest } from '@/lib/genai';
const START_MODEL_NAME = process.env.GEMINI_START_MODEL || 'gemini-2.5-flash';

// Helper encoder reused for SSE frames
const encoder = new TextEncoder();

/**
 * POST /api/chat/start - Streams a personalised greeting generated by Gemini.
 * The response is a Server-Sent Events (SSE) stream with three event types:
 *  - meta:  one-shot object { conversationId }
 *  - token: incremental chunks of the assistant greeting
 *  - done:  indicates the stream is complete
 */
export async function POST(req: Request) {
  // -------- Detect headless mode --------
  const isHeadless = req.headers.get('x-headless') === '1';

  // -------- Authorisation --------
  const authHeader = req.headers.get('authorization');
  if (!authHeader || !authHeader.startsWith('Bearer ')) {
    return NextResponse.json({ error: 'Missing authorization header' }, { status: 401 });
  }
  const idToken = authHeader.split('Bearer ')[1];
  const auth = getAuth(adminApp);
  let decodedToken;
  try {
    decodedToken = await auth.verifyIdToken(idToken);
  } catch {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }
  const userId = decodedToken.uid;
  if (!decodedToken.email) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  // -------- Fetch user profile (non-blocking for now) --------
  const userProfileDoc = await getDoc(adminDoc(db, 'users', userId));
  const userProfile = userProfileDoc.exists() ? userProfileDoc.data() : null;

  // -------- Conversation creation --------
  const conversationId = crypto.randomUUID();
  const headlessGreeting = `Hi! Welcome to the Idea Intake Portal.`;

  if (isHeadless) {
    const newConversation: DraftConversation = {
      id: conversationId,
      userId,
      status: 'draft',
      messages: [
        {
          role: 'assistant',
          content: headlessGreeting,
          timestamp: Date.now(),
        },
      ],
      state: {
        currentStep: 'init',
        missingProfileFields: [],
        collectedData: {},
        validations: {},
        language: 'en',
      },
      createdAt: Date.now(),
      updatedAt: Date.now(),
    };

    try {
      const convRef = doc(collection(db, 'conversations'), conversationId);
      await setDoc(convRef, newConversation);
    } catch (persistErr) {
      console.error('[API] chat/start headless persist error', persistErr);
      return NextResponse.json({ error: 'Failed to create conversation' }, { status: 500 });
    }

    return NextResponse.json({ conversationId });
  }

  // -------- Build Gemini prompt --------
  const defaultName = userProfile?.name?.split(' ')[0] || 'there';
  const defaultGreeting = `Hi ${defaultName}! Welcome to the AIET Intake Portal. ` +
    `I'm AIET-IntakeBot, here to help you submit tasks for automation. ` +
    `What task would you like to automate today?`;

  // We now ask Gemini for ONLY the greeting (no JSON) so we can stream it verbatim.
  const { photoUrl, ...profileWithoutPhoto } = userProfile || {}; // omit large photo URLs
  const userProfileJson = JSON.stringify(profileWithoutPhoto);
  const extractionPrompt = `You are AIET-IntakeBot from the AI Efficiency Team. ` +
    `Using the following user profile JSON: ${userProfileJson}.\n\n` +
    `Craft a short, warm, witty HTML greeting that:\n` +
    `• references the user's first name and implies their role/location without stating it word-for-word.\n` +
    `• briefly explains that this portal captures processes to automate with Generative AI.\n` +
    `• instructs the user to start by sending a short summary of the task they have in mind.\n\n` +
    `IMPORTANT: Return ONLY the greeting rich HTML format. Highlight something personal about them, use emjois if you see fit. Do NOT wrap in JSON, markdown, or any other commentary.`;

  // -------- Prepare SSE stream --------
  let accumulatedPrompt = '';

  const body = new ReadableStream({
    async start(controller) {
      try {
        // 1️⃣  Emit meta frame so the client can set conversationId immediately
        controller.enqueue(encoder.encode(`event:meta\ndata:${JSON.stringify({ conversationId })}\n\n`));

        // 2️⃣  Stream Gemini tokens
        try {
          // @ts-ignore – generateContentStream exists at runtime and returns an async iterable
          const geminiStream: any = await genAI.models.generateContentStream(
            buildRequest(START_MODEL_NAME, extractionPrompt)
          );
          // Stream each chunk of the AI's response
          for await (const chunk of geminiStream as any) {
            const rawText = chunk.text;
            if (rawText) {
              const textPart = rawText.replace(/\n/g, ' ');
              accumulatedPrompt += rawText;
              controller.enqueue(encoder.encode(`event:token\ndata:${textPart}\n\n`));
            }
          }
        } catch (gemErr) {
          console.error('[API] chat/start Gemini error (streaming)', gemErr);
          accumulatedPrompt = defaultGreeting;
          // Send fallback greeting in one go
          controller.enqueue(encoder.encode(`event:token\ndata:${defaultGreeting}\n\n`));
        }

        // 3️⃣  Persist the draft conversation
        const newConversation: DraftConversation = {
          id: conversationId,
          userId,
          status: 'draft',
          messages: [
            {
              role: 'assistant',
              content: accumulatedPrompt,
              timestamp: Date.now(),
            },
          ],
          state: {
            currentStep: 'init',
            missingProfileFields: [],
            collectedData: {},
            validations: {},
            language: 'en', // default; can be updated later via /api/chat/language
          },
          createdAt: Date.now(),
          updatedAt: Date.now(),
        };
        try {
          const convRef = doc(collection(db, 'conversations'), conversationId);
          await setDoc(convRef, newConversation);
        } catch (persistErr) {
          console.error('[API] chat/start persist error', persistErr);
        }

        // 4️⃣  Signal completion and close stream
        controller.enqueue(encoder.encode(`event:done\ndata:OK\n\n`));
        controller.close();
      } catch (outerErr) {
        console.error('[API] chat/start outer error', outerErr);
        controller.error(outerErr);
      }
    },
  });

  return new Response(body as BodyInit, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
    },
  });
} 
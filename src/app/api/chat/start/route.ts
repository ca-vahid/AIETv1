import { NextResponse } from 'next/server';
import { db } from '@/lib/firebase/firebase';
import { DraftConversation } from '@/lib/types/conversation';
import { collection, doc, setDoc, getDoc, doc as adminDoc } from 'firebase/firestore';
import { getAuth } from 'firebase-admin/auth';
import { adminApp } from '@/lib/firebase/admin';
// @ts-ignore - No types available for @google/generative-ai
import { GoogleGenerativeAI } from '@google/generative-ai';

// Initialize Gemini for start prompt generation
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');
const START_MODEL_NAME = process.env.GEMINI_START_MODEL || 'gemini-2.5-flash-preview-04-17';
const startModel = genAI.getGenerativeModel({ model: START_MODEL_NAME });

// Helper encoder reused for SSE frames
const encoder = new TextEncoder();

/**
 * POST /api/chat/start - Streams a personalised greeting generated by Gemini.
 * The response is a Server-Sent Events (SSE) stream with three event types:
 *  - meta:  one-shot object { conversationId }
 *  - token: incremental chunks of the assistant greeting
 *  - done:  indicates the stream is complete
 */
export async function POST(req: Request) {
  // -------- Authorisation --------
  const authHeader = req.headers.get('authorization');
  if (!authHeader || !authHeader.startsWith('Bearer ')) {
    return NextResponse.json({ error: 'Missing authorization header' }, { status: 401 });
  }
  const idToken = authHeader.split('Bearer ')[1];
  const auth = getAuth(adminApp);
  let decodedToken;
  try {
    decodedToken = await auth.verifyIdToken(idToken);
  } catch {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }
  const userId = decodedToken.uid;
  if (!decodedToken.email) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  // -------- Fetch user profile (non-blocking for now) --------
  const userProfileDoc = await getDoc(adminDoc(db, 'users', userId));
  const userProfile = userProfileDoc.exists() ? userProfileDoc.data() : null;

  // -------- Build Gemini prompt --------
  const defaultName = userProfile?.name?.split(' ')[0] || 'there';
  const defaultGreeting = `Hi ${defaultName}! Welcome to the AIET Intake Portal. ` +
    `I'm AIET-IntakeBot, here to help you submit tasks for automation. ` +
    `What task would you like to automate today?`;

  // We now ask Gemini for ONLY the greeting (no JSON) so we can stream it verbatim.
  const { photoUrl, ...profileWithoutPhoto } = userProfile || {}; // omit large photo URLs
  const userProfileJson = JSON.stringify(profileWithoutPhoto);
  const extractionPrompt = `You are AIET-IntakeBot from the AI Efficiency Team. ` +
    `Using the following user profile JSON: ${userProfileJson}.\n\n` +
    `Craft a short, warm, witty HTML greeting that:\n` +
    `• references the user's first name and implies their role/location without stating it word-for-word.\n` +
    `• briefly explains that this portal captures processes to automate with Generative AI.\n` +
    `• instructs the user to start by sending a short summary of the task they have in mind.\n\n` +
    `IMPORTANT: Return ONLY the greeting rich HTML format. Highlight something personal about them, use emjois if you see fit. Do NOT wrap in JSON, markdown, or any other commentary.`;

  // -------- Prepare SSE stream --------
  const conversationId = crypto.randomUUID();
  let accumulatedPrompt = '';

  const body = new ReadableStream({
    async start(controller) {
      try {
        // 1️⃣  Emit meta frame so the client can set conversationId immediately
        controller.enqueue(encoder.encode(`event:meta\ndata:${JSON.stringify({ conversationId })}\n\n`));

        // 2️⃣  Stream Gemini tokens
        try {
          // @ts-ignore – generateContentStream exists at runtime and returns an async iterable
          const geminiResult: any = await startModel.generateContentStream(extractionPrompt);
          const geminiStream: any = geminiResult.stream || geminiResult;
          for await (const chunk of geminiStream as any) {
            const rawText = (chunk as any).text();
            // Replace line breaks to keep SSE framing intact
            const textPart = rawText.replace(/\n/g, ' ');
            accumulatedPrompt += rawText;
            controller.enqueue(encoder.encode(`event:token\ndata:${textPart}\n\n`));
          }
        } catch (gemErr) {
          console.error('[API] chat/start Gemini error (streaming)', gemErr);
          accumulatedPrompt = defaultGreeting;
          // Send fallback greeting in one go
          controller.enqueue(encoder.encode(`event:token\ndata:${defaultGreeting}\n\n`));
        }

        // 3️⃣  Persist the draft conversation
        const newConversation: DraftConversation = {
          id: conversationId,
          userId,
          status: 'draft',
          messages: [
            {
              role: 'assistant',
              content: accumulatedPrompt,
              timestamp: Date.now(),
            },
          ],
          state: {
            currentStep: 'init',
            missingProfileFields: [],
            collectedData: {},
            validations: {},
            language: 'en', // default; can be updated later via /api/chat/language
          },
          createdAt: Date.now(),
          updatedAt: Date.now(),
        };
        try {
          const convRef = doc(collection(db, 'conversations'), conversationId);
          await setDoc(convRef, newConversation);
        } catch (persistErr) {
          console.error('[API] chat/start persist error', persistErr);
        }

        // 4️⃣  Signal completion and close stream
        controller.enqueue(encoder.encode(`event:done\ndata:OK\n\n`));
        controller.close();
      } catch (outerErr) {
        console.error('[API] chat/start outer error', outerErr);
        controller.error(outerErr);
      }
    },
  });

  return new Response(body as BodyInit, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      Connection: 'keep-alive',
    },
  });
} 